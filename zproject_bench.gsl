#   Generate benchmarks framework
#
#   Generates a skeleton for a new benchmark.
#   See project.xml for instructions on how to specify a benchmark.
#
#   This is a code generator built using the iMatix GSL code generation
#   language. See https://github.com/zeromq/gsl for details.
#
#   Copyright (c) the Contributors as noted in the AUTHORS file.
#   This file is part of zproject.
#
#   This Source Code Form is subject to the terms of the Mozilla Public
#   License, v. 2.0. If a copy of the MPL was not distributed with this
#   file, You can obtain one at http://mozilla.org/MPL/2.0/.

.macro generate_bench_header ()
.output "bench/bench.h"
/*  =========================================================================
    bench.h -  Benchmarking header file, contains common functionality to
               measure time, run the benchmark and calculate results.

.   for project.license
    $(string.trim (license.):block                                         )
.   endfor

$(project.GENERATED_WARNING_HEADER:)
    =========================================================================
*/

#ifndef BENCH_H
#define BENCH_H

#include "../src/$(project.prefix)_classes.h"

#ifdef __cplusplus
extern "C" {
#endif

#define MICRO_IN_SEC 1000000.00
#define SEC_IN_MIN 60

typedef struct {
    long N; // N for each run
    long R; // runs
    int64_t start;
    int64_t end;
} bench_t;

static void
s_bench_start (bench_t *self)
{
    self->start = zclock_usecs ();
}

static void
s_bench_stop (bench_t *self)
{
    self->end = zclock_usecs ();
}

static double
s_bench_iteration_speed (bench_t *self)
{
    return (self->N * self->R) / ((self->end - self->start) / MICRO_IN_SEC);
}

static double
s_bench_duration (bench_t *self)
{
    return (self->end - self->start) / MICRO_IN_SEC;
}

static void
s_bench_print_summary (bench_t *self)
{
    printf ("%ld runs, ", self->R);
    printf ("%ld iterations each run, ", self->N);
    printf ("finished in %lf seconds\\n", s_bench_duration (self));
    printf ("%.2f i/sec\\n", s_bench_iteration_speed (self) );
}

#define MEASURE(B) \\
        bench_t B; B.N = 1; B.R = 1; \\
        printf("Measuring " #B "...\\n"); \\
        s_bench_start(&B);

#define END_MEASURE(B) \\
        s_bench_stop(&B);

#define BENCHMARK(B) \\
        printf("Benchmarking " #B "...\\n"); \\
        bench_t B; B.N = 5000000; B.R = 3; \\
        s_bench_start(&B); \\
        for (int _r = 0; _r < B.R ; _r++ ) { \\
            for (int _i = 0; _i < B.N ; _i++ ) {

#define END_BENCHMARK(B) \\
            } \\
        } \\
        s_bench_stop(&B);

#define BENCHMARK_SUMMARY(B) s_bench_print_summary(&B);

#ifdef __cplusplus
}
#endif

#endif
/*
$(project.GENERATED_WARNING_HEADER:)
*/
.endmacro

.macro generate_bench_source (bench)
.if !file.exists ("bench/$(bench.name).c")
.   output "bench/$(bench.name).c"
/*  =========================================================================
    $(bench.c_name) - $(string.trim (bench.?''):no,left)

.   for project.license
    $(string.trim (license.):block                                         )
.   endfor
    =========================================================================
*/

/*
@header
    $(bench.c_name) - $(string.trim (bench.?''):no,left)
@discuss
@end
*/

#include "bench.h"

int main (void)
{
    printf ("Run benchmarks for $(bench.name):\n");
    //  TODO: Prepare benchmark

    //  Measure the execution of a code block
    //  The code block is executed once.
    MEASURE (measure_name)
    //  TODO: Insert a code block to be measured
    END_MEASURE (measure_name)
    BENCHMARK_SUMMARY(measure_name);

    //  Benchmark the execution of a code block
    //  The code block is executed 5 mio. times with 3 iterations.
    BENCHMARK (benchmark_name)
    //  TODO: Insert a code block to be benchmarked
    END_BENCHMARK (benchmark_name)
    BENCHMARK_SUMMARY(benchmark_name);

    return 0;
}
.else
.   echo "NOT regenerating an existing bench/$(bench.name).c skeleton file; but you probably should not care"
.endif
.endmacro

.macro generate_bench_makefile ()
.output "bench/Makemodule.am"
$(project.GENERATED_WARNING_HEADER:)

benchmark_progs = \\
.for bench
.   if !last()
    bench/$(bench.name) \\
.   else
    bench/$(bench.name)
.   endif
.endfor

.for bench
noinst_PROGRAMS += bench/$(bench.name)
bench_$(bench.name)_CPPFLAGS = ${AM_CPPFLAGS}
bench_$(bench.name)_LDADD = ${program_libs}
bench_$(bench.name)_SOURCES = bench/$(bench.name).c

.endfor
# Run the benchmark binaries
\.PHONY: bench
bench: \$(benchmark_progs)
\tfor f in \$^; do \$(LIBTOOL) --mode=execute \$(srcdir)/\$\$f; done

# Run the selftest binary under valgrind to check for memory leaks
bench-memcheck: \$(benchmark_progs)
\tfor f in \$^; do \\
\t\t$\(LIBTOOL) --mode=execute valgrind --tool=memcheck \\
\t\t\t--leak-check=full --show-reachable=yes --error-exitcode=1 \\
\t\t\t--suppressions=$\(srcdir)/src/.valgrind.supp \\
\t\t\t$\(VALGRIND_OPTIONS) \\
\t\t\t$\(srcdir)/\$\$f; \\
\tdone

# Run the selftest binary under valgrind to check for performance leaks
bench-callcheck: \$(benchmark_progs)
\tfor f in \$^; do \\
\t\t$\(LIBTOOL) --mode=execute valgrind --tool=callgrind \\
\t\t\t$\(VALGRIND_OPTIONS) \\
\t\t\t$\(srcdir)/\$\$f; \\
\tdone

$(project.GENERATED_WARNING_HEADER:)
.append "Makefile.am"
include \$(srcdir)/bench/Makemodule.am
.endmacro

if count (bench) > 0
    directory.create ("bench")
    generate_bench_header ()
    for bench
        generate_bench_source (bench)
    endfor
    generate_bench_makefile ()
endif
